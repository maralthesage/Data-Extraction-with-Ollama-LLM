{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction Using Mixtral:7x8b\n",
    "\n",
    "**This is a data extraction project in which we extract product attributes of individual product categories one by one.**\n",
    "**Problem**: \n",
    "- There is a large set of HTML text in an excel sheet that has all the product attributes of our products. <br>\n",
    "- The product attributes are not individually listed anywhere. <br>\n",
    "- We need a dataset of product attributes in which various properties of each product are listed separately, in order to build a PIM system, and to use specific attributes to SEO-optimize our webshop texts. <br>\n",
    "- The Challenge is that the text is not regular, different attributes come in a variety of formats from one product to the next. <br>\n",
    "- Another challenge is that we do not have a comprehensive list of product properties and that also needs to be created along the way. <br>\n",
    "\n",
    "**Solution**: \n",
    "1. The first solution was Text mining using Regular expressions. It was implemented on one product group by reading and analyzing product descriptions of many products and finding attributes and then generating the regex patterns to extract them. <br>\n",
    "Successful, but took a lot of time and energy. \n",
    "2. The second solution was to use SpaCy and NLP methods to extract adjective and prepositional groups such as \"mit Griff\" or \"mit Deckel\" to then use them for attribute generation. <br>\n",
    "This was a faster method than raw text mining, but the problem was a large number of false positives (adjectives that were not product attributes) and false negatives <br>\n",
    "(items that were not adjectives or prepositional groups but were attributes of the product nevertheless). \n",
    "3. This lead to trying out LLMs. The first attempt was with the transformers library. However, running into Langchain and Ollama, I found them to be faster solutions. <br>\n",
    "I used Ollama because it supported the Mixtral:7x8b model which is both compatible with structured outputs and also supports German language. <br>\n",
    "The result is the following code that functions much better in extracting all the relevant data required for our products.\n",
    "\n",
    "- Note: The prompt was an important part of the modeling which resulted in correct and coherent results that could be further processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from values import *\n",
    "import ollama\n",
    "import warnings\n",
    "import os\n",
    "from mistralai import Mistral\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Productgroup Number and its name\n",
    "val = Values()\n",
    "wg_list = val.wr_gr\n",
    "wg_name = val.wr_name\n",
    "client = val.client\n",
    "model = val.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the csv file that has the product information for each warengruppe (previously generated using wr_folder_building.ipynb)\n",
    "file = pd.read_csv(f'{val.parent_dir}{wg_list}/{wg_list}.csv',delimiter=';',encoding='utf-8')\n",
    "file = pd.read_csv(f'tischdecke-online.csv',delimiter=';',encoding='utf-8')\n",
    "mined_text = file.copy()\n",
    "mined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filtering only the necessary columns\n",
    "mined_text = mined_text[['NUMMER','NAME','NET_BESCHREIBUNG']]\n",
    "# mined_text = mined_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_keys = [\n",
    "    \"NUMMER\", # Produkt ID\n",
    "    \"NAME\", # 1-Stufen Sicherheitsleiter\n",
    "    \"MATERIAL\", # Aluminium, Kunststoff\n",
    "    \"PRODUKTART\", # Wasserkocher, Mobiler Grillwagen\n",
    "    \"FARBE-TEXT\", # Rot\n",
    "    \"GROESSE-TEXT\", # klein, groß\n",
    "    \"HERGESTELLT\", # Deutschland\n",
    "    \"SET\", # 3-tlg.\n",
    "    \"STUECK\", # 1 Stück\n",
    "    \"DESIGN\", # Extrabreite Stufen mit Antirutschprofil\n",
    "    \"MOTIV\", # Blumenmotiv\n",
    "    \"MUSTER\", # großer Pfingstrosen-Print\n",
    "    \"FORM\", # Rund, Quadratisch\n",
    "    \"GEWEBEART\", #Baumwolle\n",
    "    \"BREITE\", # 31,5 cm (obere Standfläche)\n",
    "    \"LAENGE\", # 14,5 cm (Trittstufen)\n",
    "    \"DURCHMESSER\", # Ø 20cm\n",
    "    \"ANDERE-ABMESSUNGEN\", # [ 10 x 15 x 5 cm (B/T/H) ]\n",
    "    \"PFLEGEHINWEIS\", # Washbarkeit und trocknerkeit\n",
    "    \"SCHUTZ\", # Teflon (TM)-Ausrüstung , Fleckenschutz\n",
    "    \"BRAND\", # Hagen Grote\n",
    "    \"QUALITAET\", # Hochfeste Aluminiumstruktur\n",
    "    \"ZERTIFIKATE\", # OEKO-TEX® STANDARD 100, BIO\n",
    "    \"ANDERE-EIGENSCHAFTEN\" # [\"Standsicher\", \"Superleicht\", \"Ultraflach\", \"Fester Stand\", \"Oberer Haltebügel\", \"Geprüfte Sicherheit\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to clean responses from the LLM\n",
    "def clean_response(response_text):\n",
    "    response_text = response_text.replace(r\"\\\\u00fc\",\"ü\")\n",
    "    try:\n",
    "        response_dict = json.loads(response_text)\n",
    "        cleaned_dict = {key: value.strip() if isinstance(value, str) else value for key, value in response_dict.items()}\n",
    "        return cleaned_dict\n",
    "\n",
    "    except json.JSONDecodeError :\n",
    "\n",
    "        print(f\"Error: The response is not a valid JSON object.\")\n",
    "        print(response_text)\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_response(response_text):\n",
    "    response_text = response_text.replace(r\"\\\\u00fc\", \"ü\")\n",
    "    try:\n",
    "        response_dict = json.loads(response_text)\n",
    "\n",
    "        # Check if response_dict is a dictionary\n",
    "        if isinstance(response_dict, dict):\n",
    "            cleaned_dict = {key: value.strip() if isinstance(value, str) else value for key, value in response_dict.items()}\n",
    "            return cleaned_dict\n",
    "\n",
    "        # Check if response_dict is a list\n",
    "        elif isinstance(response_dict, list):\n",
    "            # Clean list elements if they are strings\n",
    "            cleaned_list = [item.strip() if isinstance(item, str) else item for item in response_dict]\n",
    "            return cleaned_list\n",
    "\n",
    "        # If response_dict is neither dict nor list, return it as is\n",
    "        else:\n",
    "            return response_dict\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: The response is not a valid JSON object.\")\n",
    "        print(response_text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original model - not modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Loading the prompt and generating responses based on previous variables as well as extact instrctions\n",
    "# uncleaned_data = []\n",
    "\n",
    "# for id,name, net_beschreibung,kat_beshreibung in zip(mined_text['NUMMER'],mined_text['NAME'],mined_text['NET_BESCHREIBUNG'],mined_text['KAT_BESCHREIBUNG']):\n",
    "#     print(id,name)\n",
    "\n",
    "#     prompt = f\"\"\"[INST]\n",
    "#                 1. Extrahieren Sie die Produktattribute aus der folgenden Net_Beschreibung und geben Sie sie als gültiges JSON-Objekt in deutscher Sprache aus.\n",
    "#                 2. Verwenden Sie NUR die allowed_keys = {allowed_keys} Schlüssel und ändern Sie diese nicht.\n",
    "#                 3. Katalogue_beschreibung wird NUR berücksichtigt, wenn ein für das Modell erforderlicher Wert fehlt. Andernfalls überspringe sie.\n",
    "#                 4. Nutzen Sie ALLE erlaubten Schlüssel im JSON-Objekt und setzen Sie nicht verfügbare Werte als \"N/A\".\n",
    "#                 5. Beschränken Sie die Werte auf maximal 50 Zeichen.\n",
    "#                 6. Verwenden Sie NUR die im Text vorhandenen Informationen, ohne Schlüsse oder Vermutungen.\n",
    "#                 7. Das JSON-Objekt sollte KEINE ASCII-Kodierung enthalten.\n",
    "#                 8. Überprüfen Sie doppelt, ob die Schlüssel alle genau gleich als \"allowed_keys\" sind.\n",
    "#                 9. Achten Sie darauf, dass die Reihenfolge der Dimensionen B/T/H ist (Breite, Tiefe, Höhe).\n",
    "#                 10. Werte sollten eindeutige Wörter sein und keine \"Ja\", \"Nein\", \"True\" oder \"False\". Beispiel: DECKEL = \"Mit Deckel\".\n",
    "#                 11. Die Ausgabe sollte NUR das JSON-Objekt sein, ohne zusätzlichen Text außerhalb von geschweiften Klammern.\n",
    "#                 12. Verwenden Sie ausschließlich Informationen aus dem aktuellen Text, ohne Vorwissen oder Ableitungen.\n",
    "#                 [/INST]\n",
    "                    \n",
    "#                     NUMMER: {id}\n",
    "#                     NAME: {name}\n",
    "#                     Net_beschreibung: {net_beschreibung}\n",
    "#                     Katalogue_beschreibung:{kat_beshreibung}\n",
    "#         \"\"\"\n",
    "\n",
    "# # Generate response using Mixtral 7x8b\n",
    "#     response = ollama.generate(model='mixtral:latest', prompt=prompt)\n",
    "\n",
    "# # Clean up the response\n",
    "#     uncleaned_data.append(response['response'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified model, with Mistral API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the prompt and generating responses based on previous variables as well as extact instrctions\n",
    "uncleaned_data = []\n",
    "\n",
    "for id,name, net_beschreibung in zip(mined_text['NUMMER'],mined_text['NAME'],mined_text['NET_BESCHREIBUNG']):\n",
    "    print(id,name)\n",
    "\n",
    "    prompt = f\"\"\"[INST]\n",
    "                1. Extrahieren Sie die Produktattribute aus der folgenden Net_Beschreibung und geben Sie sie als gültiges JSON-Objekt in deutscher Sprache aus.\n",
    "                2. Verwenden Sie NUR die allowed_keys = {allowed_keys} Schlüssel und ändern Sie diese nicht.\n",
    "                3. Katalogue_beschreibung wird NUR berücksichtigt, wenn ein für das Modell erforderlicher Wert fehlt. Andernfalls überspringe sie.\n",
    "                4. Nutzen Sie ALLE erlaubten Schlüssel im JSON-Objekt und setzen Sie nicht verfügbare Werte als \"N/A\".\n",
    "                5. Beschränken Sie die Werte auf maximal 50 Zeichen.\n",
    "                6. Verwenden Sie NUR die im Text vorhandenen Informationen, ohne Schlüsse oder Vermutungen.\n",
    "                7. Das JSON-Objekt sollte KEINE ASCII-Kodierung enthalten.\n",
    "                8. Überprüfen Sie doppelt, ob die Schlüssel alle genau gleich als \"allowed_keys\" sind.\n",
    "                9. Achten Sie darauf, dass die Reihenfolge der Dimensionen B/T/H ist (Breite, Tiefe, Höhe).\n",
    "                10. Werte sollten eindeutige Wörter sein und keine \"Ja\", \"Nein\", \"True\" oder \"False\". Beispiel: DECKEL = \"Mit Deckel\".\n",
    "                11. Die Ausgabe sollte NUR das JSON-Objekt sein, ohne zusätzlichen Text außerhalb von geschweiften Klammern.\n",
    "                12. Verwenden Sie ausschließlich Informationen aus dem aktuellen Text, ohne Vorwissen oder Ableitungen.\n",
    "                [/INST]\n",
    "                    \n",
    "                    NUMMER: {id}\n",
    "                    NAME: {name}\n",
    "                    Net_beschreibung: {net_beschreibung}\n",
    "                  \n",
    "        \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    "    chat_response = client.chat.complete(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        response_format = {\n",
    "            \"type\": \"json_object\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(chat_response.choices[0].message.content)\n",
    "# # Generate response using Mixtral 7x8b\n",
    "#     response = ollama.generate(model='mixtral:latest', prompt=prompt)\n",
    "\n",
    "# # Clean up the response\n",
    "    uncleaned_data.append(chat_response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning one step further and appending responses to a new list\n",
    "new_data = []\n",
    "for id,item in enumerate(uncleaned_data):\n",
    "    item = item.replace('```',\"\")\n",
    "    item = item.replace('json',\"\")\n",
    "    # print(clean_response(item))\n",
    "    new_data.append(clean_response(item))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving clean json-objects to a json file\n",
    "with open(f'{val.parent_dir}{val.wr_gr}/{val.wr_name}_{val.wr_gr}.json', 'w', encoding=\"utf-8\") as f:\n",
    "    json.dump(new_data, f, indent=4, ensure_ascii=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating folders for each WARENGRUPPE along with the product data for that WR\n",
    "\n",
    "This is a one-time used code to structure the data so that products for each product group are in their separate folder along with their prompt format and allowed keys as well as their output csv and json files. This will structure the data so that each product group is treated individually based on its attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries and initializing values class to import the relevant variables\n",
    "import pandas as pd\n",
    "from values import *\n",
    "import os\n",
    "from dbfread import DBF\n",
    "\n",
    "val = Values()\n",
    "encoding_ = 'cp850'\n",
    "encoding_errors='replace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading data from warengruppe list, the products in the webshop and the marketing artikel list that connects the other two datas together\n",
    "warengr = pd.read_csv(val.wr_filepath,delimiter=';',encoding_errors=encoding_errors,encoding=encoding_)\n",
    "shop = pd.read_excel(val.shop_file_path,engine='openpyxl')\n",
    "marketing_art = pd.read_csv(val.marketing_artikel,delimiter=';',encoding_errors=encoding_errors)\n",
    "mark_bez_df = pd.read_csv(val.mark_bez,delimiter=';',encoding=encoding_,encoding_errors=encoding_errors)\n",
    "\n",
    "## We need the first part of the StoreId number to connect with the marketing artikel list\n",
    "# shop['NUMMER'] = shop['StoreId'].str.split().str[0]\n",
    "\n",
    "# cat_data = pd.read_csv(val.cat_data,delimiter=';',encoding_errors=encoding_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_data.reset_index(drop=True,inplace=True)\n",
    "# cat_data = cat_data[['NUMMER','BESCHREIBUNG']]\n",
    "# warengr['WAREN_GRP'] = warengr['WAREN_GRP'].fillna('')\n",
    "# marketing_art['WARENGR'] = marketing_art['WARENGR'].fillna('')\n",
    "# marketing_art[marketing_art['NUMMER'].str.contains('554HB04')]['WARENGR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketing_art['WM'].fillna(\"\",inplace=True)\n",
    "marketing_art['FARBE'].fillna(\"\",inplace=True)\n",
    "marketing_art['GROESSE'].fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "marketing_art['WARENGR'] = marketing_art['WARENGR'].astype(str)\n",
    "marketing_art['WARENGR'] = marketing_art['WARENGR'].str.replace('.0','')\n",
    "marketing_art['WARENGR'] = marketing_art['WARENGR'].str.strip()\n",
    "\n",
    "\n",
    "marketing_art = marketing_art[['WM','NUMMER','GROESSE','FARBE','WARENGR']]\n",
    "marketing_art['NUMBER'] = marketing_art['NUMMER'].str.ljust(8) + marketing_art['GROESSE'].str.ljust(4) + marketing_art['FARBE'].str.ljust(2)\n",
    "marketing_art['NUMBER'] = marketing_art['NUMBER'].str.strip()\n",
    "mark_bez_df['NUMMER'] = mark_bez_df['NUMMER'].str.strip()\n",
    "\n",
    "warengr['WAREN_GRP'] = warengr['WAREN_GRP'].astype(str)\n",
    "warengr['WAREN_GRP'] = warengr['WAREN_GRP'].str.replace('.0','')\n",
    "warengr['WAREN_GRP'] = warengr['WAREN_GRP'].str.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structure Creation\n",
    "\n",
    "In the following cell, different tables are connected together to create a list of all the artikels that are in the shop, and that have a description, so that we can extract their attributes from their description and VAR_TEXT. some lines are commented, because for example the katalog data is no longer needed for this purpose. But can be added if needed in the future.\n",
    "Also note that the folder name is now changed to Product_mining_2 instead of Product_mining. So we have two folders, and the old one is a bit processed and can be used for comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_data = []\n",
    "for num, vals in zip(warengr['WAREN_GRP'],warengr['WAREN_GRNA']):\n",
    "    ## iterating over warengruppe\n",
    "    artikels_in_wr = marketing_art[marketing_art['WARENGR'] == str(num)]\n",
    "    ## connecting marketing artikels for each warnegruppe with the shop list\n",
    "    artikels = pd.merge(artikels_in_wr,shop,how='right',left_on=\"NUMBER\",right_on=\"StoreId\")\n",
    "    ## selecting necessary columns\n",
    "    artikels = artikels[['WM','NUMMER','GROESSE','FARBE', 'NUMBER','WARENGR','Name','Beschreibung','Var_Text']]\n",
    "    # artikels = pd.merge(artikels,cat_data,how='left',on='NUMMER')\n",
    "    ## renaming columns \n",
    "    artikels = artikels.rename(columns={'Name':'NAME','Beschreibung':'NET_BESCHREIBUNG'})\n",
    "    ## data cleaning (removing html codes and unnecessary characters)\n",
    "    artikels['NET_BESCHREIBUNG'] = artikels['NET_BESCHREIBUNG'].str.replace('Â ',' ',regex=True)\n",
    "    artikels['NET_BESCHREIBUNG'] = artikels['NET_BESCHREIBUNG'].str.replace(r'(<[^>]*>)',' ',regex=True,case=False)\n",
    "    artikels['NET_BESCHREIBUNG'] = artikels['NET_BESCHREIBUNG'].str.replace(r'&nbsp_|&nbsp;|&Oslash',' ',regex=True)\n",
    "    # artikels = artikels[artikels['BESCHREIBUNG'].isna() == False]\n",
    "    ## preparing the product description to have all the information by concatenating both names and description together\n",
    "    artikels['BESCHREIBUNG'] = artikels['NAME'] + ' - ' + artikels['Var_Text'] + ' - ' + artikels['NET_BESCHREIBUNG'] \n",
    "    # artikels = artikels[artikels['WARENGR'].isna() == False]\n",
    "    artikels = artikels.drop_duplicates('NUMBER')\n",
    "    artikels = artikels.dropna(subset='NUMBER')\n",
    "    artikels = artikels[['WM','NUMMER','GROESSE','FARBE','WARENGR','NAME','BESCHREIBUNG']]\n",
    "    wg_data.append([num,vals,len(artikels)])\n",
    "\n",
    "    if len(artikels) != 0:\n",
    "        new_val = vals.replace('/','_')\n",
    "        paths = os.path.join(val.parent_dir, str(num)+'_'+str(new_val))\n",
    "        print(str(num) + ' ' + str(len(artikels)))\n",
    "        # Building folders based on the warengruppe numbers\n",
    "        if not os.path.exists(paths):\n",
    "            os.mkdir(paths) \n",
    "        artikels.to_excel(f'{paths}/{num}_{new_val}.xlsx', engine='xlsxwriter',index=False)\n",
    "        \n",
    "wg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for creating the Product_mining lists based on Marketing Artikel Bezeichnung data BANAM1,2, and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wg_data = []\n",
    "for num, vals in zip(warengr['WAREN_GRP'],warengr['WAREN_GRNA']):\n",
    "    ## iterating over warengruppe\n",
    "    artikels_in_wr = marketing_art[marketing_art['WARENGR'] == str(num)]\n",
    "    ## connecting marketing artikels for each warnegruppe with the shop list\n",
    "    # artikels = pd.merge(artikels_in_wr,shop,how='left',left_on=\"NUMBER\",right_on=\"StoreId\")\n",
    "    artikels = pd.merge(artikels_in_wr,mark_bez_df,how='left',left_on='NUMBER',right_on='NUMMER')\n",
    "    # artikels = artikels.dropna(subset='WARENGR')\n",
    "\n",
    "    artikels = pd.merge(artikels,shop,how='right',left_on=\"NUMBER\",right_on=\"StoreId\")\n",
    "\n",
    "\n",
    "    artikels = artikels.rename(columns={'NUMMER_x':'NUMMER'})\n",
    "    artikels = artikels.drop_duplicates('NUMMER')\n",
    "    artikels = artikels.dropna(subset='NUMMER')\n",
    "    artikels = artikels[['WM','NUMMER','GROESSE','FARBE','WARENGR','BANAME1','BANAME2','BANAME3']]\n",
    "    wg_data.append([num,vals,len(artikels)])\n",
    "\n",
    "    if len(artikels) != 0:\n",
    "        new_val = vals.replace('/','_')\n",
    "        paths = os.path.join(val.parent_dir, str(num)+'_'+str(new_val))\n",
    "        print(paths)\n",
    "        # print(path)\n",
    "        # Building folders based on the warengruppe numbers\n",
    "        if not os.path.exists(paths):\n",
    "            os.mkdir(paths) \n",
    "        # artikels.to_csv(f'{paths}/{num}_{new_val}.csv',encoding='utf-8', sep=',',index=False)\n",
    "        # Apply the cleaning function to all string elements in the DataFrame\n",
    "        # artikels = artikels.apply(convert_encoding)\n",
    "        # artikels.to_csv(f'{paths}/{num}_{new_val}.csv',index=False,sep=';',encoding='utf-8')\n",
    "        # artikels.to_excel(f'{paths}/{num}_{new_val}.xlsx',index=False, engine='openpyxl')\n",
    "        artikels.to_excel(f'{paths}/{num}_{new_val}_shop.xlsx', engine='xlsxwriter',index=False)\n",
    "\n",
    "        # artikels.to_json(f'{paths}/{num}_{new_val}.json',index=False)\n",
    "    # else:\n",
    "    #     paths = os.path.join(val.parent_dir, str(num))\n",
    "    #     for file in os.listdir(paths):\n",
    "    #         os.remove(os.path.join(paths,file))\n",
    "    #     print(paths)\n",
    "    #     os.rmdir(paths)\n",
    "\n",
    "        ## inserting the csv file of the products for each warengruppe and adding a prompt placeholder text (to be filled)\n",
    "        # with open(f'{path}/prompt_{num}.txt','w') as txt:\n",
    "        #     txt.write(\"prompt-to-be-filled\")\n",
    "        \n",
    "wg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving WG_artikel_3 which is list of WGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wg_df = pd.DataFrame(wg_data,columns=['WG_ID','WG_NAME','ITEMS_IN_WG'])\n",
    "# # wg_df.to_csv('/Users/maralsheikhzadeh/Documents/Codes/useful-exports/WG_artikels_3.csv',sep=';',index=False,encoding='utf-8')\n",
    "# wg_df.to_excel('/Users/maralsheikhzadeh/Documents/Codes/useful-exports/WG_artikels_3.xlsx',index=False, engine='openpyxl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
